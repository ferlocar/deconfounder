{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and pre-process ACIC data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zymu_129047995.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [8.97567934419504, 7.746484983793969, 6.784245182459641]\n",
      "IMPROVEMENT: [4.4, -0.73, 4.89]\n",
      "-------\n",
      "zymu_129047999.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [34.61506060168141, 44.71371100971731, 38.62145136801542]\n",
      "IMPROVEMENT: [1.01, 0.0, -1.01]\n",
      "-------\n",
      "zymu_129048005.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [81.13748241300347, 88.78370036322146, 88.1644590386937]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048010.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.4}\n",
      "MSE: [37.6914988110243, 38.88301654084893, 38.42863924773463]\n",
      "IMPROVEMENT: [0.0, 0.0, -7.61]\n",
      "-------\n",
      "zymu_129048011.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [13.496790103437583, 12.717424155318456, 15.39468288549989]\n",
      "IMPROVEMENT: [-8.55, 0.0, -9.29]\n",
      "-------\n",
      "zymu_129048013.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [31.815242048275643, 58.73737895994711, 38.30942123631963]\n",
      "IMPROVEMENT: [24.3, -0.35, 17.96]\n",
      "-------\n",
      "zymu_129048016.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [27.17705801058668, 28.11388084755713, 26.30574339885558]\n",
      "IMPROVEMENT: [3.54, 0.0, 10.62]\n",
      "-------\n",
      "zymu_129048023.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [38.198783038094874, 34.5540148072438, 41.67270385226773]\n",
      "IMPROVEMENT: [0.0, 0.0, -5.57]\n",
      "-------\n",
      "zymu_129048024.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 230}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [57.04028735343216, 66.58184581540897, 56.665855299645926]\n",
      "IMPROVEMENT: [3.47, -3.1, 3.47]\n",
      "-------\n",
      "zymu_129048027.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [6.6093920471254615, 3.6823322269942667, 5.242630507968775]\n",
      "IMPROVEMENT: [-10.8, 0.0, 0.35]\n",
      "-------\n",
      "zymu_129048030.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 230}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.4}\n",
      "MSE: [9.357220590766351, 8.6089350879071, 10.38842168833125]\n",
      "IMPROVEMENT: [14.42, 11.35, 9.51]\n",
      "-------\n",
      "zymu_129048033.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 200}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [25.181971212823246, 28.717287734215844, 24.9153679494917]\n",
      "IMPROVEMENT: [12.85, 11.84, 12.85]\n",
      "-------\n",
      "zymu_129048034.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [6.74252926028212, 4.037622727299142, 6.882554290176649]\n",
      "IMPROVEMENT: [1.68, 0.0, -6.15]\n",
      "-------\n",
      "zymu_129048035.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [21.76947158567002, 27.716862005330004, 21.805098104991142]\n",
      "IMPROVEMENT: [2.0, -10.29, 2.0]\n",
      "-------\n",
      "zymu_129048040.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [11.447536095017973, 4.488408945534072, 8.916675433375504]\n",
      "IMPROVEMENT: [0.0, 0.0, -3.22]\n",
      "-------\n",
      "zymu_129048041.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [15.907949234689118, 19.09308052387658, 15.092310390507476]\n",
      "IMPROVEMENT: [-2.23, 0.0, -5.45]\n",
      "-------\n",
      "zymu_129048046.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [13.57160459498122, 11.615185396447883, 11.284144180206379]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048047.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [15.907454939587067, 15.992844620065004, 17.669306437147203]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048063.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 220}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [15.042679525635368, 14.949826969768475, 18.60063824171167]\n",
      "IMPROVEMENT: [0.0, 0.0, -12.33]\n",
      "-------\n",
      "zymu_129048073.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [26.810328066055778, 37.44318296763372, 26.545531624447293]\n",
      "IMPROVEMENT: [0.74, 0.0, -5.67]\n",
      "-------\n",
      "zymu_129048074.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [66.82561414672234, 58.714223232876265, 60.12197479674594]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048079.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [16.566974824359814, 12.908422581903022, 12.719913188989125]\n",
      "IMPROVEMENT: [0.0, 0.0, -4.26]\n",
      "-------\n",
      "zymu_129048084.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit deconfounder tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [25.053045556094908, 25.203966666704776, 24.66548435295143]\n",
      "IMPROVEMENT: [117.24, 146.55, 146.55]\n",
      "-------\n",
      "zymu_129048098.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 100}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [17.89615914826332, 23.639092424748178, 22.63700044734615]\n",
      "IMPROVEMENT: [94.92, 94.35, 78.53]\n",
      "-------\n",
      "zymu_129048099.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 50}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [20.44999477216869, 24.19989619501063, 20.355677232984892]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048104.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 100}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.25}\n",
      "MSE: [30.933942003223653, 26.78313412576594, 29.139183077563448]\n",
      "IMPROVEMENT: [0.0, 0.0, -1.85]\n",
      "-------\n",
      "zymu_129048108.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 100}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [17.343578791297336, 13.65532269399068, 16.96089222257631]\n",
      "IMPROVEMENT: [0.0, 0.0, -2.56]\n",
      "-------\n",
      "zymu_129048112.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [17.500897672452595, 21.394772767677026, 16.318254148582984]\n",
      "IMPROVEMENT: [0.0, -4.79, 0.0]\n",
      "-------\n",
      "zymu_129048113.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [25.189953154026487, 22.439086481346276, 18.60955172380712]\n",
      "IMPROVEMENT: [11.43, 11.43, 11.43]\n",
      "-------\n",
      "zymu_129048116.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [12.88019217602748, 18.934902622734636, 14.729359302611886]\n",
      "IMPROVEMENT: [-208.16, -173.47, -205.1]\n",
      "-------\n",
      "zymu_129048126.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [14.314468959214752, 13.39537007689426, 13.353479107118389]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048134.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.1}\n",
      "MSE: [26.37982464316841, 29.456581863261608, 44.57601411268241]\n",
      "IMPROVEMENT: [0.0, 0.0, -11.64]\n",
      "-------\n",
      "zymu_129048135.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [6.9130425874795565, 4.11280438126783, 13.31316971080139]\n",
      "IMPROVEMENT: [5.83, 8.07, 1.35]\n",
      "-------\n",
      "zymu_129048151.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 180}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [45.238580895954584, 42.438001375166046, 43.95332518907152]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048161.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 260}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [24.485915498897118, 19.910629924409655, 19.109763033563894]\n",
      "IMPROVEMENT: [0.0, 0.0, 2.69]\n",
      "-------\n",
      "zymu_129048163.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [28.832275707522037, 27.420508377478054, 28.001246256823087]\n",
      "IMPROVEMENT: [-1.04, 0.0, -1.04]\n",
      "-------\n",
      "zymu_129048170.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [19.04247087677711, 19.594531626833135, 18.70036170490621]\n",
      "IMPROVEMENT: [9.64, 8.54, 10.19]\n",
      "-------\n",
      "zymu_129048175.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [27.483047661387882, 30.23825611017732, 27.22791770747287]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048176.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [56.569460323948725, 56.924551847420155, 55.99437199071792]\n",
      "IMPROVEMENT: [-3.57, 12.14, 35.0]\n",
      "-------\n",
      "zymu_129048182.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [10.749247550515959, 11.146289213705007, 9.917945734593518]\n",
      "IMPROVEMENT: [0.0, -13.59, -5.76]\n",
      "-------\n",
      "zymu_129048185.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [7.110286225681107, 13.315518365731617, 7.001976298215197]\n",
      "IMPROVEMENT: [17.61, 6.25, 17.61]\n",
      "-------\n",
      "zymu_129048196.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 220}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [12.218496212098724, 8.065329532691106, 7.979096012138107]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048201.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [34.62597707680851, 35.89999975211792, 45.23177941763351]\n",
      "IMPROVEMENT: [0.2, 0.0, -11.2]\n",
      "-------\n",
      "zymu_129048208.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [51.87957556924948, 60.03027721801787, 52.04233203138513]\n",
      "IMPROVEMENT: [4.99, -2.49, 4.99]\n",
      "-------\n",
      "zymu_129048220.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [2.8960934000078686, 1.8578063383974983, 2.4821954260559123]\n",
      "IMPROVEMENT: [0.0, 0.0, -2.96]\n",
      "-------\n",
      "zymu_129048221.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 170}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 40}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [36.09498636262932, 40.8697713126524, 33.75834513662394]\n",
      "IMPROVEMENT: [4.26, -0.67, 4.26]\n",
      "-------\n",
      "zymu_129048223.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 220}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [22.119780529926903, 18.753429831574127, 20.017232766319445]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048226.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [19.310649352498334, 19.32551198080188, 19.401470779143256]\n",
      "IMPROVEMENT: [-1400.0, -625.0, -1200.0]\n",
      "-------\n",
      "zymu_129048227.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [21.17075596106834, 22.324361473728494, 20.607605149988366]\n",
      "IMPROVEMENT: [2.8, 1.6, 2.8]\n",
      "-------\n",
      "zymu_129048230.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 60}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 10}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [15.311139041635299, 27.606243047970466, 20.08268958143926]\n",
      "IMPROVEMENT: [19.02, 10.6, 13.86]\n",
      "-------\n",
      "zymu_129048232.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 180}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [46.2469372078897, 52.37075616508702, 45.76182190026911]\n",
      "IMPROVEMENT: [-480.0, -413.33, -593.33]\n",
      "-------\n",
      "zymu_129048234.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [23.55962560264915, 28.12703584941676, 24.891723420589095]\n",
      "IMPROVEMENT: [6.36, 0.0, 6.36]\n",
      "-------\n",
      "zymu_129048237.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 180}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [4.793807935778201, 3.435384506469849, 6.992456660222124]\n",
      "IMPROVEMENT: [0.0, 0.0, -14.95]\n",
      "-------\n",
      "zymu_129048238.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [17.267350364241324, 18.31099287460291, 12.963218785934433]\n",
      "IMPROVEMENT: [-0.49, -2.46, -0.49]\n",
      "-------\n",
      "zymu_129048243.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [6.073844406520111, 5.37276007142192, 5.553034165506449]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048248.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [11.800670053850334, 13.447199330890086, 10.530251151918499]\n",
      "IMPROVEMENT: [0.0, -5.11, -3.16]\n",
      "-------\n",
      "zymu_129048250.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [16.651484597968583, 18.13836212481694, 18.158591932628763]\n",
      "IMPROVEMENT: [2.5, 0.0, 2.95]\n",
      "-------\n",
      "zymu_129048251.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [34.41868209680562, 47.744180222578365, 38.185369218661044]\n",
      "IMPROVEMENT: [12.57, 0.0, 13.09]\n",
      "-------\n",
      "zymu_129048252.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 100}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 200}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [32.188963549160796, 31.912894584813344, 30.746108775760362]\n",
      "IMPROVEMENT: [0.0, 0.0, -1.4]\n",
      "-------\n",
      "zymu_129048253.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.25}\n",
      "MSE: [16.30122120711226, 23.26138891474034, 21.762467112172825]\n",
      "IMPROVEMENT: [7.14, -2.3, 1.84]\n",
      "-------\n",
      "zymu_129048255.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [31.33353424954182, 33.721179661566296, 30.5064984405479]\n",
      "IMPROVEMENT: [4.12, 0.0, 4.12]\n",
      "-------\n",
      "zymu_129048256.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 220}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 260}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [53.24406831139936, 55.64906670343351, 54.05871921951569]\n",
      "IMPROVEMENT: [-5.3, 0.0, -2.33]\n",
      "-------\n",
      "zymu_129048258.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 50}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.25}\n",
      "MSE: [11.951346714022156, 13.315642407798288, 17.112776002044455]\n",
      "IMPROVEMENT: [14.74, 14.37, 11.38]\n",
      "-------\n",
      "zymu_129048260.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [13.556304675972973, 17.162699386822553, 10.61491360674866]\n",
      "IMPROVEMENT: [8.98, 0.0, 8.98]\n",
      "-------\n",
      "zymu_129048267.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 40}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [22.12602584341181, 19.362516123836386, 21.73946719855372]\n",
      "IMPROVEMENT: [2.66, 5.07, 2.66]\n",
      "-------\n",
      "zymu_129048268.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 180}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [20.06212320016311, 18.92222450366338, 19.346102673462244]\n",
      "IMPROVEMENT: [0.0, 0.0, -5.9]\n",
      "-------\n",
      "zymu_129048269.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 230}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 220}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [21.685238303094124, 18.625849277585473, 18.33781921403217]\n",
      "IMPROVEMENT: [0.0, 0.0, -2.76]\n",
      "-------\n",
      "zymu_129048271.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [24.29533855590315, 24.107359630019914, 23.503170893624617]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048273.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 190}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [15.584171183494382, 15.17381609395495, 15.495677868606444]\n",
      "IMPROVEMENT: [12.74, 10.51, 12.1]\n",
      "-------\n",
      "zymu_129048278.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [19.941655355824576, 23.936354045489438, 18.696934948747774]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048279.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 260}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.4}\n",
      "MSE: [41.94125353032262, 40.150447404535385, 40.25841401809807]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048287.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 230}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [61.75204996631835, 68.52448963303152, 61.40398305593561]\n",
      "IMPROVEMENT: [3.8, 0.0, 3.8]\n",
      "-------\n",
      "zymu_129048290.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [55.45785275483288, 65.34019080473807, 60.57542792374766]\n",
      "IMPROVEMENT: [31.14, 9.34, 25.26]\n",
      "-------\n",
      "zymu_129048291.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [5.312893677087686, 3.164679652153587, 7.729015756787395]\n",
      "IMPROVEMENT: [0.0, -1.75, -24.02]\n",
      "-------\n",
      "zymu_129048295.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 80}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [17.6692345206932, 19.71724592643271, 16.179403291610146]\n",
      "IMPROVEMENT: [-10.63, -4.33, 0.79]\n",
      "-------\n",
      "zymu_129048298.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 290}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [11.27833628239552, 11.427358146159483, 10.370426364640977]\n",
      "IMPROVEMENT: [-101.53, -100.0, -100.0]\n",
      "-------\n",
      "zymu_129048300.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [10.324771577240005, 10.35124431418315, 8.36519486928449]\n",
      "IMPROVEMENT: [6.44, 6.92, 5.73]\n",
      "-------\n",
      "zymu_129048303.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 200}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [25.421789724872546, 24.762638268405247, 31.7740937126852]\n",
      "IMPROVEMENT: [0.0, 0.0, -5.41]\n",
      "-------\n",
      "zymu_129048305.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.15}\n",
      "MSE: [16.38671984694374, 18.051921127996664, 28.03070872750024]\n",
      "IMPROVEMENT: [0.0, -5.35, -16.7]\n",
      "-------\n",
      "zymu_129048310.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 200}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.3}\n",
      "MSE: [23.855173336449685, 33.665542053781756, 26.846742290776383]\n",
      "IMPROVEMENT: [6.84, 3.13, 7.41]\n",
      "-------\n",
      "zymu_129048311.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 160}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 110}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [42.063170839040474, 44.68128315168076, 41.39154779066238]\n",
      "IMPROVEMENT: [2.46, 1.37, -0.82]\n",
      "-------\n",
      "zymu_129048313.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 200}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [36.702332510714434, 37.62027056473732, 36.03988797938239]\n",
      "IMPROVEMENT: [-5.07, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048315.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.35}\n",
      "MSE: [12.282432596557431, 13.639863109325077, 15.94229018851045]\n",
      "IMPROVEMENT: [8.56, 0.0, 7.18]\n",
      "-------\n",
      "zymu_129048318.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 90}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [6.045171674591811, 11.883831163924599, 5.642157361764249]\n",
      "IMPROVEMENT: [23.6, -3.11, 26.09]\n",
      "-------\n",
      "zymu_129048321.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [8.981377562269476, 7.714753560185841, 8.373666789000143]\n",
      "IMPROVEMENT: [0.0, 0.0, -3.92]\n",
      "-------\n",
      "zymu_129048325.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [14.609810660727998, 9.684837725935404, 8.897156395503998]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048335.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [24.76684278437447, 25.542908470310852, 25.14798634412982]\n",
      "IMPROVEMENT: [-1.41, 0.0, -0.8]\n",
      "-------\n",
      "zymu_129048352.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 140}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 50}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [35.56562428852725, 24.76995041965468, 33.67569934456699]\n",
      "IMPROVEMENT: [-1.04, 0.0, -0.17]\n",
      "-------\n",
      "zymu_129048357.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [8.51084451340894, 9.89724401125703, 7.6272385748965466]\n",
      "IMPROVEMENT: [0.0, -2.67, -9.09]\n",
      "-------\n",
      "zymu_129048359.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 260}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 130}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [21.50696307378427, 22.92211896642053, 19.460811149118015]\n",
      "IMPROVEMENT: [0.29, 0.87, -5.25]\n",
      "-------\n",
      "zymu_129048361.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 120}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.2}\n",
      "MSE: [25.46600190901449, 25.056492206099108, 29.773256419022665]\n",
      "IMPROVEMENT: [3.75, -0.33, 0.98]\n",
      "-------\n",
      "zymu_129048362.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 170}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [21.855760397304213, 18.19140947213511, 15.264839814956373]\n",
      "IMPROVEMENT: [0.0, -3.2, -0.84]\n",
      "-------\n",
      "zymu_129048364.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 190}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 170}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [17.53886778579917, 16.116486157170606, 14.325241964101675]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048366.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 270}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.45}\n",
      "MSE: [9.329893613883867, 4.775965008888235, 5.247826441270494]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048370.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [11.066663474148559, 10.027252700560723, 7.813290455744306]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n",
      "zymu_129048373.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 30}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 40}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [18.128685967591142, 26.38797514226479, 16.395194508716113]\n",
      "IMPROVEMENT: [9.34, 5.56, 8.59]\n",
      "-------\n",
      "zymu_129048375.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 280}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 210}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [33.24621814132806, 30.862436087202994, 30.29283296968121]\n",
      "IMPROVEMENT: [-19.74, 0.0, -7.57]\n",
      "-------\n",
      "zymu_129048381.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 150}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [20.980111012991117, 25.021572307842582, 20.71333494864663]\n",
      "IMPROVEMENT: [0.0, 0.0, -0.24]\n",
      "-------\n",
      "zymu_129048386.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 70}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [12.753240066063757, 14.42755598156064, 12.089353232804301]\n",
      "IMPROVEMENT: [10.3, 6.5, 10.3]\n",
      "-------\n",
      "zymu_129048397.csv\n",
      "Fit causal tree with an OBSERVATIONAL data set of 4000 individuals\n",
      "{'min_samples_leaf': 250}\n",
      "Fit causal tree with an EXPERIMENTAL data set of 1000 individuals\n",
      "{'min_samples_leaf': 240}\n",
      "Fit deconfounder tree\n",
      "{'min_weight_fraction_leaf': 0.5}\n",
      "MSE: [28.73247941398848, 28.915012031684583, 29.596917079213746]\n",
      "IMPROVEMENT: [0.0, 0.0, 0.0]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "### LINES TO IMPORT THE DECONFOUNDER PACKAGE IN THE PARENT FOLDER ###\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "### IMPORTS\n",
    "from deconfounder.causal_tree import CausalTree\n",
    "from deconfounder.deconfounder_tree import DeconfounderTree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "def fit_causal_tree(X, y):\n",
    "    # Fit and tune causal tree\n",
    "    start_time = time.time()\n",
    "    tuned_parameters = [{'min_samples_leaf': range(10, 300, 10)}]\n",
    "    causal_tree = GridSearchCV(CausalTree(random_state=42), tuned_parameters, cv=5)\n",
    "    causal_tree.fit(X, y)   \n",
    "    #print(\"Best parameters set found on development set:\")\n",
    "    print(causal_tree.best_params_)\n",
    "    #print(\"--- Time to fit (and tune) causal tree %s seconds ---\" % (time.time() - start_time))\n",
    "    return causal_tree\n",
    "\n",
    "def evaluate(preds, effs):\n",
    "    mse = np.mean((preds - effs)**2)\n",
    "    avg_effect = round(np.mean(effs), 2)\n",
    "    avg_with_policy = round(np.mean((preds > 0) * effs), 2)\n",
    "    improvement = round(100*avg_with_policy/avg_effect-100, 2)\n",
    "    return mse, improvement\n",
    "\n",
    "##### LOAD FEATURE DATA\n",
    "df_X = pd.read_csv(\"../data/x.csv\")\n",
    "df_X = pd.get_dummies(df_X)\n",
    "all_feature_names = df_X.columns\n",
    "\n",
    "##### GET RESPONSE FILES\n",
    "response_files = [f for f in listdir(\"../data/77\") if isfile(join(\"../data/77\", f))]\n",
    "\n",
    "mse_rows = []\n",
    "improvement_rows = []\n",
    "#### CONDUCT ANALYSIS FOR EACH FILE\n",
    "for f_name in response_files:\n",
    "    np.random.seed(42)\n",
    "    print(f_name)\n",
    "    ##### LOAD RESPONSE DATA\n",
    "    # Merge with response info\n",
    "    df = pd.concat([df_X, pd.read_csv(f\"../data/77/{f_name}\")], axis=1)\n",
    "    # Create observed response and assignment variables\n",
    "    df.rename(columns={\"z\": \"z_obs\"}, inplace=True)\n",
    "    df['effs'] = df.mu1 - df.mu0\n",
    "    df['y_obs'] = df.y1 * df.z_obs + df.y0 * (1 - df.z_obs)\n",
    "    df['z_exp'] = np.random.binomial(1, df.z_obs.mean(), df.shape[0])\n",
    "    df['y_exp'] = df.y1 * df.z_exp + df.y0 * (1 - df.z_exp)\n",
    "\n",
    "    ##### INTRODUCE CONFOUNDING \n",
    "    n_confounders = 5 \n",
    "    corr_matrix = df[all_feature_names.values.tolist() + ['z_obs', 'y_obs']].corr()\n",
    "    corr_matrix\n",
    "    ranked_features = (corr_matrix.z_obs.abs() * corr_matrix.y_obs.abs()).sort_values(ascending=False).index.values\n",
    "    confounders = ranked_features[~np.isin(ranked_features, ['z_obs', 'y_obs'])][:n_confounders]\n",
    "    feature_names = all_feature_names[~np.isin(all_feature_names, confounders)]\n",
    "    X = df[feature_names].copy()\n",
    "\n",
    "    ##### SPLIT INTO TRAIN AND TEST \n",
    "    is_train = np.full(df.shape[0], True)\n",
    "    is_train[:802] = False\n",
    "    np.random.shuffle(is_train)\n",
    "\n",
    "    ##### FIT AND EVALUATE OBSERVATIONAL AND EXPERIMENTAL TREES\n",
    "    trees = []\n",
    "    mse_all = []\n",
    "    improvement_all = []\n",
    "    exp_size = 1000\n",
    "    for d_type in [\"OBSERVATIONAL\", \"EXPERIMENTAL\"]:\n",
    "        if d_type == \"OBSERVATIONAL\":\n",
    "            size = 4000\n",
    "            y = df.y_obs\n",
    "            z = df.z_obs\n",
    "        else:\n",
    "            size = exp_size\n",
    "            y = df.y_exp\n",
    "            z = df.z_exp\n",
    "        print(f\"Fit causal tree with an {d_type} data set of {size} individuals\")\n",
    "        X_with_treatment = X.copy()\n",
    "        X_with_treatment['treated'] = z\n",
    "        causal_tree = fit_causal_tree(X_with_treatment[is_train][:size], y[is_train][:size])\n",
    "        trees.append(causal_tree)\n",
    "        preds = causal_tree.predict(X_with_treatment[~is_train])\n",
    "        mse, improvement = evaluate(preds, df.effs[~is_train])\n",
    "        mse_all.append(mse)\n",
    "        improvement_all.append(improvement)\n",
    "\n",
    "    ##### MERGE OBSERVATIONAL AND EXPERIMENTAL DATA\n",
    "    X_all = pd.concat([X[is_train], X[is_train][:exp_size]], ignore_index=True)\n",
    "    X_all['experiment'] = False\n",
    "    X_all.loc[4000:, 'experiment'] = True\n",
    "    X_all['treated'] = False\n",
    "    X_all.loc[~X_all.experiment.values, 'treated'] = df[is_train].z_obs.values\n",
    "    X_all.loc[X_all.experiment.values, 'treated'] = df[is_train][:exp_size].z_exp.values\n",
    "    y_all = pd.concat([df[is_train].y_obs, df[is_train][:exp_size].y_exp], ignore_index=True)\n",
    "    X_all = X_all.sample(frac=1)\n",
    "    y_all = y_all.loc[X_all.index.values]\n",
    "\n",
    "    ##### BUILD DECONFOUNDER TREE\n",
    "    print(\"Fit deconfounder tree\")\n",
    "    tuned_parameters = [{'min_weight_fraction_leaf': np.array(range(5, 55, 5))/100}]\n",
    "    deconfounder = GridSearchCV(DeconfounderTree(random_state=42), tuned_parameters, cv=5)\n",
    "    deconfounder.fit(X_all, y_all)\n",
    "    print(deconfounder.best_params_)\n",
    "    pd.Series(deconfounder.predict(X_all)).value_counts()\n",
    "\n",
    "    ##### TEST DECONFOUNDED MODEL\n",
    "    X_test = X[~is_train]\n",
    "    bias_preds = deconfounder.predict(X_test)\n",
    "    obs_preds = trees[0].predict(X_test)\n",
    "    preds = obs_preds - bias_preds\n",
    "    mse, improvement = evaluate(preds, df.effs[~is_train])\n",
    "    mse_all.append(mse)\n",
    "    improvement_all.append(improvement)\n",
    "    print(f\"MSE: {mse_all}\")\n",
    "    print(f\"IMPROVEMENT: {improvement_all}\")\n",
    "    mse_rows.append(mse_all)\n",
    "    improvement_rows.append(improvement_all)\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFFECT ESTIMATION\n",
      "Number of times it hurts observational estimations: 35\n",
      "Number of times it is irrelevant for observational estimations: 0\n",
      "Number of times it helps observational estimations: 65\n",
      "Number of times it makes the best estimations 48\n",
      "DECISION MAKING\n",
      "Number of times it hurts observational decisions: 44\n",
      "Number of times it is irrelevant for observational decisions: 36\n",
      "Number of times it helps observational decisions: 20\n",
      "Number of times it makes the best decisions 11\n"
     ]
    }
   ],
   "source": [
    "mse_cols = [\"MSE_Obs\", \"MSE_Exp\", \"MSE_Comb\"]\n",
    "imp_cols = [\"Imp_Obs\", \"Imp_Exp\", \"Imp_Comb\"]\n",
    "results = pd.concat([pd.DataFrame(mse_rows, columns=[\"MSE_Obs\", \"MSE_Exp\", \"MSE_Comb\"]),\n",
    "                     pd.DataFrame(improvement_rows, columns=[\"Imp_Obs\", \"Imp_Exp\", \"Imp_Comb\"])], axis=1)\n",
    "print(\"EFFECT ESTIMATION\")\n",
    "print(\"Number of times it hurts observational estimations:\", (results[\"MSE_Comb\"] > results[\"MSE_Obs\"]).sum())\n",
    "print(\"Number of times it is irrelevant for observational estimations:\", (results[\"MSE_Comb\"] == results[\"MSE_Obs\"]).sum())\n",
    "print(\"Number of times it helps observational estimations:\", (results[\"MSE_Comb\"] < results[\"MSE_Obs\"]).sum())\n",
    "print(\"Number of times it makes the best estimations\", (results[mse_cols].idxmin(axis=1) == \"MSE_Comb\").sum())\n",
    "print(\"DECISION MAKING\")\n",
    "print(\"Number of times it hurts observational decisions:\", (results[\"Imp_Comb\"] < results[\"Imp_Obs\"]).sum())\n",
    "print(\"Number of times it is irrelevant for observational decisions:\", (results[\"Imp_Comb\"] == results[\"Imp_Obs\"]).sum())\n",
    "print(\"Number of times it helps observational decisions:\", (results[\"Imp_Comb\"] > results[\"Imp_Obs\"]).sum())\n",
    "print(\"Number of times it makes the best decisions\", (results[imp_cols].idxmax(axis=1) == \"Imp_Comb\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE_Obs</th>\n",
       "      <th>MSE_Exp</th>\n",
       "      <th>MSE_Comb</th>\n",
       "      <th>Imp_Obs</th>\n",
       "      <th>Imp_Exp</th>\n",
       "      <th>Imp_Comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.975679</td>\n",
       "      <td>7.746485</td>\n",
       "      <td>6.784245</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.615061</td>\n",
       "      <td>44.713711</td>\n",
       "      <td>38.621451</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.137482</td>\n",
       "      <td>88.783700</td>\n",
       "      <td>88.164459</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.691499</td>\n",
       "      <td>38.883017</td>\n",
       "      <td>38.428639</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.496790</td>\n",
       "      <td>12.717424</td>\n",
       "      <td>15.394683</td>\n",
       "      <td>-8.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.815242</td>\n",
       "      <td>58.737379</td>\n",
       "      <td>38.309421</td>\n",
       "      <td>24.30</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>17.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.177058</td>\n",
       "      <td>28.113881</td>\n",
       "      <td>26.305743</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.198783</td>\n",
       "      <td>34.554015</td>\n",
       "      <td>41.672704</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57.040287</td>\n",
       "      <td>66.581846</td>\n",
       "      <td>56.665855</td>\n",
       "      <td>3.47</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.609392</td>\n",
       "      <td>3.682332</td>\n",
       "      <td>5.242631</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.357221</td>\n",
       "      <td>8.608935</td>\n",
       "      <td>10.388422</td>\n",
       "      <td>14.42</td>\n",
       "      <td>11.35</td>\n",
       "      <td>9.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.181971</td>\n",
       "      <td>28.717288</td>\n",
       "      <td>24.915368</td>\n",
       "      <td>12.85</td>\n",
       "      <td>11.84</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.742529</td>\n",
       "      <td>4.037623</td>\n",
       "      <td>6.882554</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.769472</td>\n",
       "      <td>27.716862</td>\n",
       "      <td>21.805098</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-10.29</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.447536</td>\n",
       "      <td>4.488409</td>\n",
       "      <td>8.916675</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.907949</td>\n",
       "      <td>19.093081</td>\n",
       "      <td>15.092310</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.571605</td>\n",
       "      <td>11.615185</td>\n",
       "      <td>11.284144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.907455</td>\n",
       "      <td>15.992845</td>\n",
       "      <td>17.669306</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.042680</td>\n",
       "      <td>14.949827</td>\n",
       "      <td>18.600638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.810328</td>\n",
       "      <td>37.443183</td>\n",
       "      <td>26.545532</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>66.825614</td>\n",
       "      <td>58.714223</td>\n",
       "      <td>60.121975</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.566975</td>\n",
       "      <td>12.908423</td>\n",
       "      <td>12.719913</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25.053046</td>\n",
       "      <td>25.203967</td>\n",
       "      <td>24.665484</td>\n",
       "      <td>117.24</td>\n",
       "      <td>146.55</td>\n",
       "      <td>146.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17.896159</td>\n",
       "      <td>23.639092</td>\n",
       "      <td>22.637000</td>\n",
       "      <td>94.92</td>\n",
       "      <td>94.35</td>\n",
       "      <td>78.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.449995</td>\n",
       "      <td>24.199896</td>\n",
       "      <td>20.355677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.933942</td>\n",
       "      <td>26.783134</td>\n",
       "      <td>29.139183</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.343579</td>\n",
       "      <td>13.655323</td>\n",
       "      <td>16.960892</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17.500898</td>\n",
       "      <td>21.394773</td>\n",
       "      <td>16.318254</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25.189953</td>\n",
       "      <td>22.439086</td>\n",
       "      <td>18.609552</td>\n",
       "      <td>11.43</td>\n",
       "      <td>11.43</td>\n",
       "      <td>11.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.880192</td>\n",
       "      <td>18.934903</td>\n",
       "      <td>14.729359</td>\n",
       "      <td>-208.16</td>\n",
       "      <td>-173.47</td>\n",
       "      <td>-205.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>41.941254</td>\n",
       "      <td>40.150447</td>\n",
       "      <td>40.258414</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>61.752050</td>\n",
       "      <td>68.524490</td>\n",
       "      <td>61.403983</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>55.457853</td>\n",
       "      <td>65.340191</td>\n",
       "      <td>60.575428</td>\n",
       "      <td>31.14</td>\n",
       "      <td>9.34</td>\n",
       "      <td>25.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5.312894</td>\n",
       "      <td>3.164680</td>\n",
       "      <td>7.729016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>17.669235</td>\n",
       "      <td>19.717246</td>\n",
       "      <td>16.179403</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>11.278336</td>\n",
       "      <td>11.427358</td>\n",
       "      <td>10.370426</td>\n",
       "      <td>-101.53</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>-100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10.324772</td>\n",
       "      <td>10.351244</td>\n",
       "      <td>8.365195</td>\n",
       "      <td>6.44</td>\n",
       "      <td>6.92</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>25.421790</td>\n",
       "      <td>24.762638</td>\n",
       "      <td>31.774094</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>16.386720</td>\n",
       "      <td>18.051921</td>\n",
       "      <td>28.030709</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.35</td>\n",
       "      <td>-16.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>23.855173</td>\n",
       "      <td>33.665542</td>\n",
       "      <td>26.846742</td>\n",
       "      <td>6.84</td>\n",
       "      <td>3.13</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>42.063171</td>\n",
       "      <td>44.681283</td>\n",
       "      <td>41.391548</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>36.702333</td>\n",
       "      <td>37.620271</td>\n",
       "      <td>36.039888</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>12.282433</td>\n",
       "      <td>13.639863</td>\n",
       "      <td>15.942290</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.045172</td>\n",
       "      <td>11.883831</td>\n",
       "      <td>5.642157</td>\n",
       "      <td>23.60</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>26.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.981378</td>\n",
       "      <td>7.714754</td>\n",
       "      <td>8.373667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>14.609811</td>\n",
       "      <td>9.684838</td>\n",
       "      <td>8.897156</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>24.766843</td>\n",
       "      <td>25.542908</td>\n",
       "      <td>25.147986</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>35.565624</td>\n",
       "      <td>24.769950</td>\n",
       "      <td>33.675699</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.510845</td>\n",
       "      <td>9.897244</td>\n",
       "      <td>7.627239</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>-9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>21.506963</td>\n",
       "      <td>22.922119</td>\n",
       "      <td>19.460811</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>25.466002</td>\n",
       "      <td>25.056492</td>\n",
       "      <td>29.773256</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>21.855760</td>\n",
       "      <td>18.191409</td>\n",
       "      <td>15.264840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>-0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>17.538868</td>\n",
       "      <td>16.116486</td>\n",
       "      <td>14.325242</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.329894</td>\n",
       "      <td>4.775965</td>\n",
       "      <td>5.247826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>11.066663</td>\n",
       "      <td>10.027253</td>\n",
       "      <td>7.813290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18.128686</td>\n",
       "      <td>26.387975</td>\n",
       "      <td>16.395195</td>\n",
       "      <td>9.34</td>\n",
       "      <td>5.56</td>\n",
       "      <td>8.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33.246218</td>\n",
       "      <td>30.862436</td>\n",
       "      <td>30.292833</td>\n",
       "      <td>-19.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20.980111</td>\n",
       "      <td>25.021572</td>\n",
       "      <td>20.713335</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>12.753240</td>\n",
       "      <td>14.427556</td>\n",
       "      <td>12.089353</td>\n",
       "      <td>10.30</td>\n",
       "      <td>6.50</td>\n",
       "      <td>10.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>28.732479</td>\n",
       "      <td>28.915012</td>\n",
       "      <td>29.596917</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSE_Obs    MSE_Exp   MSE_Comb  Imp_Obs  Imp_Exp  Imp_Comb\n",
       "0    8.975679   7.746485   6.784245     4.40    -0.73      4.89\n",
       "1   34.615061  44.713711  38.621451     1.01     0.00     -1.01\n",
       "2   81.137482  88.783700  88.164459     0.00     0.00      0.00\n",
       "3   37.691499  38.883017  38.428639     0.00     0.00     -7.61\n",
       "4   13.496790  12.717424  15.394683    -8.55     0.00     -9.29\n",
       "5   31.815242  58.737379  38.309421    24.30    -0.35     17.96\n",
       "6   27.177058  28.113881  26.305743     3.54     0.00     10.62\n",
       "7   38.198783  34.554015  41.672704     0.00     0.00     -5.57\n",
       "8   57.040287  66.581846  56.665855     3.47    -3.10      3.47\n",
       "9    6.609392   3.682332   5.242631   -10.80     0.00      0.35\n",
       "10   9.357221   8.608935  10.388422    14.42    11.35      9.51\n",
       "11  25.181971  28.717288  24.915368    12.85    11.84     12.85\n",
       "12   6.742529   4.037623   6.882554     1.68     0.00     -6.15\n",
       "13  21.769472  27.716862  21.805098     2.00   -10.29      2.00\n",
       "14  11.447536   4.488409   8.916675     0.00     0.00     -3.22\n",
       "15  15.907949  19.093081  15.092310    -2.23     0.00     -5.45\n",
       "16  13.571605  11.615185  11.284144     0.00     0.00      0.00\n",
       "17  15.907455  15.992845  17.669306     0.00     0.00      0.00\n",
       "18  15.042680  14.949827  18.600638     0.00     0.00    -12.33\n",
       "19  26.810328  37.443183  26.545532     0.74     0.00     -5.67\n",
       "20  66.825614  58.714223  60.121975     0.00     0.00      0.00\n",
       "21  16.566975  12.908423  12.719913     0.00     0.00     -4.26\n",
       "22  25.053046  25.203967  24.665484   117.24   146.55    146.55\n",
       "23  17.896159  23.639092  22.637000    94.92    94.35     78.53\n",
       "24  20.449995  24.199896  20.355677     0.00     0.00      0.00\n",
       "25  30.933942  26.783134  29.139183     0.00     0.00     -1.85\n",
       "26  17.343579  13.655323  16.960892     0.00     0.00     -2.56\n",
       "27  17.500898  21.394773  16.318254     0.00    -4.79      0.00\n",
       "28  25.189953  22.439086  18.609552    11.43    11.43     11.43\n",
       "29  12.880192  18.934903  14.729359  -208.16  -173.47   -205.10\n",
       "..        ...        ...        ...      ...      ...       ...\n",
       "70  41.941254  40.150447  40.258414     0.00     0.00      0.00\n",
       "71  61.752050  68.524490  61.403983     3.80     0.00      3.80\n",
       "72  55.457853  65.340191  60.575428    31.14     9.34     25.26\n",
       "73   5.312894   3.164680   7.729016     0.00    -1.75    -24.02\n",
       "74  17.669235  19.717246  16.179403   -10.63    -4.33      0.79\n",
       "75  11.278336  11.427358  10.370426  -101.53  -100.00   -100.00\n",
       "76  10.324772  10.351244   8.365195     6.44     6.92      5.73\n",
       "77  25.421790  24.762638  31.774094     0.00     0.00     -5.41\n",
       "78  16.386720  18.051921  28.030709     0.00    -5.35    -16.70\n",
       "79  23.855173  33.665542  26.846742     6.84     3.13      7.41\n",
       "80  42.063171  44.681283  41.391548     2.46     1.37     -0.82\n",
       "81  36.702333  37.620271  36.039888    -5.07     0.00      0.00\n",
       "82  12.282433  13.639863  15.942290     8.56     0.00      7.18\n",
       "83   6.045172  11.883831   5.642157    23.60    -3.11     26.09\n",
       "84   8.981378   7.714754   8.373667     0.00     0.00     -3.92\n",
       "85  14.609811   9.684838   8.897156     0.00     0.00      0.00\n",
       "86  24.766843  25.542908  25.147986    -1.41     0.00     -0.80\n",
       "87  35.565624  24.769950  33.675699    -1.04     0.00     -0.17\n",
       "88   8.510845   9.897244   7.627239     0.00    -2.67     -9.09\n",
       "89  21.506963  22.922119  19.460811     0.29     0.87     -5.25\n",
       "90  25.466002  25.056492  29.773256     3.75    -0.33      0.98\n",
       "91  21.855760  18.191409  15.264840     0.00    -3.20     -0.84\n",
       "92  17.538868  16.116486  14.325242     0.00     0.00      0.00\n",
       "93   9.329894   4.775965   5.247826     0.00     0.00      0.00\n",
       "94  11.066663  10.027253   7.813290     0.00     0.00      0.00\n",
       "95  18.128686  26.387975  16.395195     9.34     5.56      8.59\n",
       "96  33.246218  30.862436  30.292833   -19.74     0.00     -7.57\n",
       "97  20.980111  25.021572  20.713335     0.00     0.00     -0.24\n",
       "98  12.753240  14.427556  12.089353    10.30     6.50     10.30\n",
       "99  28.732479  28.915012  29.596917     0.00     0.00      0.00\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/results.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deconfounder]",
   "language": "python",
   "name": "conda-env-deconfounder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
