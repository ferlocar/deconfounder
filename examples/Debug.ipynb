{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and create data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LINES TO IMPORT THE DECONFOUNDER PACKAGE IN THE PARENT FOLDER ###\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "### IMPORTS\n",
    "from deconfounder.causal_tree import CausalTree\n",
    "from deconfounder.causal_forest import CausalForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import time\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/criteo-uplift-v2.1.csv\")\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "all_features = df.columns.values[:12].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the feature that is correalted the most with the outcome and remove that feature (i.e., the confounder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f9\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df[all_features + ['visit']].corr()\n",
    "confounder = corr_matrix['visit'][:-1].sort_values().index.values[-1]\n",
    "print(confounder)\n",
    "limited_features = list(all_features)\n",
    "limited_features.remove(confounder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain observational data. Drop observations using the confounder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observational (naive) setup\n",
      "Size of data set: 6,297,527\n",
      "Avg. Outcome (treated): 5.31%\n",
      "Avg. Outcome (control): 1.23%\n",
      "Estimated avg. effect: 4.08%\n",
      "-------------\n",
      "Experimental setup\n",
      "Size of data set: 6,297,527\n",
      "Avg. Outcome (treated): 4.86%\n",
      "Avg. Outcome (control): 3.8%\n",
      "Estimated avg. effect: 1.06%\n",
      "-------------\n",
      "Entire data\n",
      "Size of data set: 13,979,592\n",
      "Avg. Outcome (treated): 4.85%\n",
      "Avg. Outcome (control): 3.82%\n",
      "Estimated avg. effect: 1.03%\n"
     ]
    }
   ],
   "source": [
    "def print_outcomes(data):\n",
    "    means = data.groupby('treatment').visit.mean()\n",
    "    print(f\"Size of data set: {data.shape[0]:,}\")\n",
    "    print(f\"Avg. Outcome (treated): {np.round(means.loc[1]*100, 2)}%\")\n",
    "    print(f\"Avg. Outcome (control): {np.round(means.loc[0]*100, 2)}%\")\n",
    "    print(f\"Estimated avg. effect: {np.round((means.loc[1]-means.loc[0])*100, 2)}%\")\n",
    "\n",
    "train_frac = 0.5\n",
    "train_size = int(df.shape[0]*train_frac)\n",
    "obs_df = df[:train_size]\n",
    "train_df = df[:train_size]\n",
    "drop_frac = 0.1\n",
    "\n",
    "conf_ranking = obs_df[confounder].rank(method=\"first\")\n",
    "keep =  ((obs_df.treatment == 1) & (conf_ranking > int(train_size * drop_frac))) | \\\n",
    "        ((obs_df.treatment == 0) & (conf_ranking < int(train_size * (1 - drop_frac))))\n",
    "obs_df = train_df[keep]\n",
    "print(\"Observational (naive) setup\")\n",
    "print_outcomes(obs_df)\n",
    "print(\"-------------\")\n",
    "exp_df = train_df.sample(n=obs_df.shape[0],random_state=42)\n",
    "print(\"Experimental setup\")\n",
    "print_outcomes(exp_df)\n",
    "print(\"-------------\")\n",
    "print(\"Entire data\")\n",
    "print_outcomes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build causal tree using observational data. Control for observable confounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree(df_causal, tree_type=CausalForest, min_samples_leaf=5000, tune=False, params=None, scoring=None, verbose=True):    \n",
    "    X = df_causal[limited_features + ['treatment']].rename(columns={\"treatment\":\"treated\"})\n",
    "    y =  df_causal.visit\n",
    "    # Fit and tune causal tree\n",
    "    start_time = time.time()\n",
    "    if tune:\n",
    "        if params is None:\n",
    "            params = range(1000, 10000, 1000)\n",
    "        tuned_parameters = [{'min_samples_leaf': params}]\n",
    "        grid_tree = GridSearchCV(tree_type(random_state=42, n_estimators=10), tuned_parameters, cv=4, \n",
    "                                 verbose=10, n_jobs=4, scoring=scoring)\n",
    "        grid_tree.fit(X, y)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(grid_tree.best_params_)\n",
    "        tree_model = grid_tree.best_estimator_\n",
    "    else:\n",
    "        tree_model = tree_type(min_samples_leaf=min_samples_leaf, random_state=42, n_estimators=10)\n",
    "        tree_model.fit(X, y)\n",
    "    if verbose:\n",
    "        print(\"--- Time to fit (and tune) causal tree %s seconds ---\" % (time.time() - start_time))\n",
    "    return tree_model\n",
    "\n",
    "#obs_tree = fit_tree(obs_df, tune=True, params=[8000, 16000, 32000, 64000, 128000])\n",
    "#Best parameters set found on development set:\n",
    "#{'min_samples_leaf': 32000}\n",
    "#--- Time to fit (and tune) causal tree 1082.7572462558746 seconds ---\n",
    "#obs_tree = fit_tree(obs_df, min_samples_leaf=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Best parameters set found on development set:\n",
      "{'min_samples_leaf': 1000}\n",
      "--- Time to fit (and tune) causal tree 5.552044630050659 seconds ---\n"
     ]
    }
   ],
   "source": [
    "limited_exp = exp_df.sample(50000,random_state=42)\n",
    "limited_tree = fit_tree(limited_exp, tune=True, params=np.arange(1, 11)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time to fit (and tune) causal tree 0.6478450298309326 seconds ---\n",
      "--- Time to fit (and tune) causal tree 1.7934596538543701 seconds ---\n",
      "--- Time to fit (and tune) causal tree 5.774129629135132 seconds ---\n",
      "--- Time to fit (and tune) causal tree 14.570174932479858 seconds ---\n"
     ]
    }
   ],
   "source": [
    "curve_sizes = np.array([50000, 100000, 200000, 400000])\n",
    "for exp_size in curve_sizes:\n",
    "    subset_exp = exp_df.sample(exp_size,random_state=42)\n",
    "    subset_tree = fit_tree(subset_exp, tune=False, min_samples_leaf=limited_tree.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_tree.min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_tree(limited_exp, tune=False, min_samples_leaf=limited_tree.min_samples_leaf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
